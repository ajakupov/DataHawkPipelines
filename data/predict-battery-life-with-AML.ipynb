{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install required libraries\n",
    "\n",
    "After your install these libraries it is recommended that you **restart the notebook kernel** from the Kernel menu above. After restarting the kernel, start from the **Predicting Car Battery Failure** section.\n",
    "\n",
    "You can ignore any incompatibility errors. Please run the cells below only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U azureml-sdk[automl]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Car Battery Failure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your goal in this notebook is to **predict how much time a car battery has left until it is expected to fail**. You are provided training data that includes telemetry from different vehicles, as well as the expected battery life that remains. From this you will train a model that given just the vehicle telemetry predicts the expected battery life. \n",
    "\n",
    "You will use compute resources provided by Azure Machine Learning (AML) to **remotely** train a **set** of models using **Automated Machine Learning**, evaluate performance of each model and pick the best performing model to deploy as a web service hosted by **Azure Container Instance**.\n",
    "\n",
    "Because you will be using the Azure Machine Learning SDK, you will be able to provision all your required Azure resources directly from this notebook, without having to use the Azure Portal to create any resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the following cell by selecting the `>|Run` button in the command bar above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants, you can leave these values as they\n",
    "experiment_name = 'automl-regression'\n",
    "project_folder = './automl-regression'\n",
    "\n",
    "# this is the URL to the CSV file containing the training data\n",
    "data_url = \"https://databricksdemostore.blob.core.windows.net/data/connected-car/training-formatted.csv\"\n",
    "\n",
    "# this is the URL to the CSV file containing a small set of test data\n",
    "test_data_url = \"https://databricksdemostore.blob.core.windows.net/data/connected-car/fleet-formatted.csv\"\n",
    "\n",
    "# provide the pre-created CPU machine learning compute found under the Compute > Training Clusters section\n",
    "cluster_name = \"aml-compute-cpu\"\n",
    "aci_service_name ='contoso-service'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Azure Machine Learning SDK provides a comprehensive set of a capabilities that you can use directly within a notebook including:\n",
    "- Creating a **Workspace** that acts as the root object to organize all artifacts and resources used by Azure Machine Learning.\n",
    "- Creating **Experiments** in your Workspace that capture versions of the trained model along with any desired model performance telemetry. Each time you train a model and evaluate its results, you can capture that run (model and telemetry) within an Experiment.\n",
    "- Creating **Compute** resources that can be used to scale out model training, so that while your notebook may be running in a lightweight container in Azure Notebooks, your model training can actually occur on a powerful cluster that can provide large amounts of memory, CPU or GPU. \n",
    "- Using **Automated Machine Learning (AutoML)** to automatically train multiple versions of a model using a mix of different ways to prepare the data and different algorithms and hyperparameters (algorithm settings) in search of the model that performs best according to a performance metric that you specify. \n",
    "- Packaging a Docker **Image** that contains everything your trained model needs for scoring (prediction) in order to run as a web service.\n",
    "- Deploying your Image to either Azure Kubernetes or Azure Container Instances, effectively hosting the **Web Service**.\n",
    "\n",
    "In Azure Notebooks, all of the libraries needed for Azure Machine Learning are pre-installed. To use them, you just need to import them. Run the following cell to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import urllib.request\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.compute import AksCompute, ComputeTarget\n",
    "from azureml.core.webservice import Webservice, AksWebservice\n",
    "from azureml.core.image import Image\n",
    "from azureml.core.model import Model\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.train.automl.run import AutoMLRun\n",
    "from azureml.core import Workspace\n",
    "from azureml.data.azure_storage_datastore import AzureBlobDatastore\n",
    "from azureml.core import Dataset\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to an Azure Machine Learning Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to connect to your Azure Machine Learning **Workspace**.\n",
    "\n",
    "**Important Note**: You maybe be prompted to login in the text that is output below the cell. Be sure to navigate to the URL displayed and enter the code that is provided. Once you have entered the code, return to this notebook and wait for the output to read `Workspace configuration succeeded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "print(ws)\n",
    "print('Workspace configuration succeeded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a summary of the current environment \n",
    "output = {}\n",
    "output['SDK version'] = azureml.core.VERSION\n",
    "output['Subscription ID'] = ws.subscription_id\n",
    "output['Workspace'] = ws.name\n",
    "output['Resource Group'] = ws.resource_group\n",
    "output['Location'] = ws.location\n",
    "output['Project Directory'] = project_folder\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.DataFrame(data=output, index=['']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Workspace Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create a new Experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment(ws, experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get and explore the Vehicle Telemetry Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to download and examine the vehicle telemetry data. The model you will build will try to predict how many days until the battery has a freeze event. Which features (columns) do you think will be useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_url)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remotely train multiple models using Auto ML and Azure ML Compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cells, you will *not* train the model against the data you just downloaded using the resources provided by the VM. Instead, you will deploy an Azure ML Compute cluster that will download the data and use Auto ML to train multiple models, evaluate the performance and allow you to retrieve the best model that was trained. In other words, all of the training will be performed remotely with respect to this notebook. \n",
    "\n",
    "\n",
    "As you will see this is almost entirely done thru configuration, with very little code required. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Azure Machine Learning TabularDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the training dataset to the project_folder, and then upload the data to the default workspace datastore which is backed by the Azure blob storage. Next, using the training data saved in the default workspace datastore, we will create an unregistered TabularDataset pointing to the path in the datastore. This dataset reference, will allow us to seamlessly access the training data during model training without worrying about connection strings or data paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create project folder\n",
    "if not os.path.exists(project_folder):\n",
    "    os.makedirs(project_folder)\n",
    "\n",
    "# download the training dataset from data_url to the project folder\n",
    "urllib.request.urlretrieve(data_url, os.path.join(project_folder, 'training-formatted.csv'))\n",
    "\n",
    "# upload training dataset to default workspace datastore\n",
    "datastore = ws.get_default_datastore()\n",
    "datastore.upload_files(files = [os.path.join(project_folder, 'training-formatted.csv')],\n",
    "                       target_path = 'train-dataset/tabular/',\n",
    "                       overwrite = True,\n",
    "                       show_progress = True)\n",
    "\n",
    "# create TabularDataset reference\n",
    "dataset = Dataset.Tabular.from_delimited_files(path = [(datastore, \n",
    "                                                        'train-dataset/tabular/training-formatted.csv')])\n",
    "\n",
    "# target or label column name\n",
    "target_column_name = 'Survival_In_Days'\n",
    "\n",
    "# preview the first 5 rows of the dataset\n",
    "dataset.take(5).to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create AML Compute Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are ready to create the compute cluster. Run the following cell to create a new compute cluster (or retrieve the existing cluster if it already exists). The code below will create a *CPU based* cluster where each node in the cluster is of the size `STANDARD_DS3_V2`, and the cluster will have *1* node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create AML CPU based Compute Cluster\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target.')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS3_V2',\n",
    "                                                           max_nodes=1)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "    compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "# Use the 'status' property to get a detailed status for the current AmlCompute. \n",
    "print(compute_target.status.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run our Experiment on AML Compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate an Automated ML Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to configure the Auto ML run. In short what you are configuring here is the training of a regressor model that will attempt to predict the value of the first feature (`Survival_in_days`) based on all the other features in the data set. The run is configured to try at most 3 iterations where no iteration can run longer that 2 minutes. \n",
    "\n",
    "Additionally, the data will be automatically pre-processed in different ways as a part of the automated model training (as indicated by the `preprocess` attribute having a value of `True`). This is a very powerful feature of Auto ML as it tries many best practices approaches for you, and saves you a lot of time and effort in the process.\n",
    "\n",
    "The goal of Auto ML in this case is to find the best models that result, as measure by the normalized root mean squared error metric (as indicated by the `primary_metric` attribute). The error is basically a measure of what the model predicts versus what was provided as the \"answer\" in the training data. In short, AutoML will try to get the error as low as possible when trying its combination of approaches.  \n",
    "\n",
    "The local path to the script you created to retrieve the data is supplied to the AutoMLConfig, ensuring the file is made available to the remote cluster. The actual execution of this training will occur on the compute cluster you created previously. \n",
    "\n",
    "In general, the AutoMLConfig is very flexible, allowing you to specify all of the following:\n",
    "- Task type (classification, regression, forecasting)\n",
    "- Number of algorithm iterations and maximum time per iteration\n",
    "- Accuracy metric to optimize\n",
    "- Algorithms to blacklist (skip)/whitelist (include)\n",
    "- Number of cross-validations\n",
    "- Compute targets\n",
    "- Training data\n",
    "\n",
    "Run the following cell to create the configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_config = AutoMLConfig(task = 'regression',\n",
    "                             iterations = 3,\n",
    "                             iteration_timeout_minutes = 5, \n",
    "                             max_cores_per_iteration = 10,\n",
    "                             featurization='auto',\n",
    "                             primary_metric='normalized_root_mean_squared_error',\n",
    "                             n_cross_validations = 5,\n",
    "                             debug_log = 'automl.log',\n",
    "                             verbosity = logging.DEBUG,\n",
    "                             training_data = dataset, \n",
    "                             label_column_name=target_column_name,\n",
    "                             compute_target = compute_target,\n",
    "                             path = project_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to execute the experiment on the remote compute cluster.\n",
    "\n",
    "This will remotely train multiple models, evaluate them and allow you review the performance characteristics of each one, as well as to pick the *best model* that was trained and download it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_run = experiment.submit(automl_config, show_output=False)\n",
    "remote_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the above cell completes, the run is starting but will likely have a status of **Preparing** for you. To wait for the run to complete before continuing (and to view the training status updates as they happen), run the next cell.\n",
    "\n",
    "Run the next cell, and wait for run status to be in **Completed** state.\n",
    "\n",
    "*Note: The first time you run this, it will take about 15 minutes to complete as the cluster is configured and then the AutoML job is run*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(remote_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List the Experiments from your Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Azure Machine Learning SDK, you can retrieve any of the experiments in your Workspace and drill into the details of any runs the experiment contains. Run the following cell to explore the number of runs by experiment name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_list = Experiment.list(workspace=ws)\n",
    "\n",
    "summary_df = pd.DataFrame(index = ['No of Runs'])\n",
    "pattern = re.compile('^AutoML_[^_]*$')\n",
    "for experiment in experiment_list:\n",
    "    all_runs = list(experiment.get_runs())\n",
    "    automl_runs = []\n",
    "    for run in all_runs:\n",
    "        if(pattern.match(run.id)):\n",
    "            automl_runs.append(run)    \n",
    "    summary_df[experiment.name] = [len(automl_runs)]\n",
    "    \n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "summary_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List the Automated ML Runs for the Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, you can view all of the runs that ran supporting Auto ML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "proj = ws.experiments[experiment_name]\n",
    "summary_df = pd.DataFrame(index = ['Type', 'Status', 'Primary Metric', 'Iterations', 'Compute', 'Name'])\n",
    "pattern = re.compile('^AutoML_[^_]*$')\n",
    "all_runs = list(proj.get_runs(properties={'azureml.runsource': 'automl'}))\n",
    "for run in all_runs:\n",
    "    if(pattern.match(run.id)):\n",
    "        properties = run.get_properties()\n",
    "        tags = run.get_tags()\n",
    "        amlsettings = json.loads(properties['AMLSettingsJsonString'])\n",
    "        if 'iterations' in tags:\n",
    "            iterations = tags['iterations']\n",
    "        else:\n",
    "            iterations = properties['num_iterations']\n",
    "        summary_df[run.id] = [amlsettings['task_type'], run.get_details()['status'], properties['primary_metric'], iterations, properties['target'], amlsettings['name']]\n",
    "    \n",
    "from IPython.display import HTML\n",
    "projname_html = HTML(\"<h3>{}</h3>\".format(proj.name))\n",
    "\n",
    "from IPython.display import display\n",
    "display(projname_html)\n",
    "display(summary_df.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Automated ML Run Details\n",
    "For a particular run, you can display the details of how the run performed against the performance metric. The Azure Machine Learning SDK includes a built-in widget that graphically summarizes the run. \n",
    "\n",
    "Execute the following cell to see it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = remote_run.id\n",
    "\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "ml_run = AutoMLRun(experiment=experiment, run_id=run_id)\n",
    "\n",
    "RunDetails(ml_run).show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the best run and the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point you have multiple runs, each with a different trained models. How can you get the model that performed the best? Run the following cells to learn how."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_run, fitted_model = remote_run.get_output()\n",
    "print(best_run)\n",
    "print(fitted_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can query for the best run when evaluated using a specific metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show run and model by a specific metric\n",
    "lookup_metric = \"root_mean_squared_error\"\n",
    "best_run, fitted_model = remote_run.get_output(metric = lookup_metric)\n",
    "print(best_run)\n",
    "print(fitted_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can retrieve a specific iteration from a run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show run and model from iteration 0\n",
    "iteration = 0\n",
    "first_run, first_model = remote_run.get_output(iteration=iteration)\n",
    "print(first_run)\n",
    "print(first_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point you now have a model you could use for predicting the time until battery failure. You would typically use this model in one of two ways:\n",
    "- Use the model file within other notebooks to batch score predictions.\n",
    "- Deploy the model file as a web service that applications can call. \n",
    "\n",
    "In the following, you will explore the latter option to deploy the best model as a web service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the best model \n",
    "With a run object in hand, it is trivial to download the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch the best model\n",
    "best_run.download_file(\"outputs/model.pkl\",\n",
    "                       output_file_path = \"./model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the Model as a Web Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Azure Machine Learning provides a Model Registry that acts like a version controlled repository for each of your trained models. To version a model, you use  the SDK as follows. Run the following cell to register the best model with Azure Machine Learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register the model for deployment\n",
    "model = Model.register(model_path = \"model.pkl\",\n",
    "                       model_name = \"model.pkl\",\n",
    "                       tags = {'area': \"auto\", 'type': \"regression\"},\n",
    "                       description = \"Contoso Auto model to predict battery failure\",\n",
    "                       workspace = ws)\n",
    "\n",
    "print(model.name, model.description, model.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have a model added to the registry in this way, you can deploy web services that pull their model directly from this repository when they first start up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Scoring File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Azure Machine Learning SDK gives you control over the logic of the web service, so that you can define how it retrieves the model and how the model is used for scoring. This is an important bit of flexibility. For example, you often have to prepare any input data before sending it to your model for scoring. You can define this data preparation logic (as well as the model loading approach) in the scoring file. \n",
    "\n",
    "Run the following cell to create a scoring file that will be included in the Docker Image that contains your deployed web service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile scoring_service.py\n",
    "import pickle\n",
    "import json\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import azureml.train.automl\n",
    "import joblib\n",
    "from azureml.core.model import Model\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    model_path = Model.get_model_path('model.pkl') # this name is model.id of model that we want to deploy\n",
    "    # deserialize the model file back into a sklearn model\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "def run(rawdata):\n",
    "    try:\n",
    "        data = pd.read_json(rawdata,orient=\"split\")\n",
    "        result = model.predict(data)\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        return json.dumps({\"error\": result})\n",
    "    return json.dumps({\"result\":result.tolist()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environments\n",
    "\n",
    "Azure ML environments are an encapsulation of the environment where your machine learning training happens. They define Python packages, environment variables, Docker settings and other attributes in declarative fashion. Environments are versioned: you can update them and retrieve old versions to revisit and review your work.\n",
    "\n",
    "Environments allow you to:\n",
    "* Encapsulate dependencies of your training process, such as Python packages and their versions.\n",
    "* Reproduce the Python environment on your local computer in a remote run on VM or ML Compute cluster\n",
    "* Reproduce your experimentation environment in production setting.\n",
    "* Revisit and audit the environment in which an existing model was trained.\n",
    "\n",
    "Environment, compute target and training script together form run configuration: the full specification of training run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and register your environment\n",
    "\n",
    "You can manage environments by registering them. This allows you to track their versions, and reuse them in future runs. For example, once you've constructed an environment that meets your requirements, you can register it and use it in other experiments so as to standardize your workflow.\n",
    "\n",
    "If you register the environment with same name, the version number is increased by one. Note that Azure ML keeps track of differences between the version, so if you re-register an identical version, the version number is not increased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "myEnv = Environment.from_conda_specification('myenv', './automl_dependencies.yml')\n",
    "myEnv.register(workspace=ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy ACI Hosted Web Service\n",
    "\n",
    "If you want more control over how your model is run, if it uses another framework, or if it has special runtime requirements, you can instead specify your own environment and scoring method. Custom environments can be used for any model you want to deploy.\n",
    "\n",
    "In previous code, you specified the model's runtime environment by creating an [Environment](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.environment%28class%29?view=azure-ml-py) object and providing the [CondaDependencies](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.conda_dependencies.condadependencies?view=azure-ml-py) needed by your model.\n",
    "\n",
    "In the following cells you will use the Azure Machine Learning SDK to package the model and scoring script in a container, and deploy that container to an Azure Container Instance.\n",
    "\n",
    "Run the following cell: you may be waiting 20-25 minutes for completion, while the Running tag adds progress dots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "inference_config = InferenceConfig(entry_script='scoring_service.py', environment=myEnv)\n",
    "aci_config = AciWebservice.deploy_configuration(\n",
    "    cpu_cores = 1, \n",
    "    memory_gb = 1, \n",
    "    tags = {'name': 'aci-cluster'}, \n",
    "    description = 'Scoring web service.')\n",
    "\n",
    "from azureml.core import Webservice\n",
    "\n",
    "service_name = 'predict-battery-life'\n",
    "\n",
    "webservice = Model.deploy(workspace=ws,\n",
    "                       name=service_name,\n",
    "                       models=[model],\n",
    "                       inference_config=inference_config,\n",
    "                       deployment_config=aci_config, \n",
    "                       overwrite=True)\n",
    "webservice.wait_for_deployment(show_output=True)\n",
    "print(webservice.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the deployed web service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the deployed web service ready, you are now ready to test calling the service with some car telemetry to see the scored results. There are three ways to approach this:\n",
    "1. You could use the `Webservice` object that you acquired in the previous cell to call the service directly.\n",
    "2. You could use the `Webservice` class to get a reference to a deployed web service by name.\n",
    "3. You could use any client capable of making a REST call.\n",
    "\n",
    "In this notebook, we will take the first approach. Run the following cells to retrieve the web service by name and then to invoke it using some sample car telemetry.\n",
    "\n",
    "The output of this cell will be an array of numbers, where each number represents the expected battery lifetime in days for the corresponding row of vehicle data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# load some test vehicle data that the model has not seen\n",
    "test_data = pd.read_csv(test_data_url)\n",
    "\n",
    "# prepare the data and select five vehicles\n",
    "test_data = test_data.drop(columns=[\"Car_ID\", \"Battery_Age\"])\n",
    "test_data.rename(columns={'Twelve_hourly_temperature_forecast_for_next_31_days_reversed': 'Twelve_hourly_temperature_history_for_last_31_days_before_death_last_recording_first'}, inplace=True)\n",
    "test_data_json = test_data.iloc[:5, 0:73].to_json(orient=\"split\")\n",
    "prediction = webservice.run(input_data = test_data_json)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
